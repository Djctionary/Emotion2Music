# ğŸµ Emotion2Music

Transform your emotions into music! This application uses deep learning to analyze your emotional keywords and find the perfect matching music.

## âœ¨ Features

- ğŸ­ **Emotion Analysis**: Convert text keywords to emotional dimensions (Valence, Arousal, Dominance)
- ğŸ’« **Interactive Bubble Interface**: Add keywords as animated bubbles with smooth transitions
- ğŸµ **Music Matching**: Find songs that match your emotional state
- ğŸ¥ **BPM Prediction**: Predict the tempo that fits your mood
- ğŸ§ **Instant Playback**: Stream music directly in the browser
- ğŸ¨ **Beautiful UI**: Modern, gradient-based interface with drag-and-drop visual metaphor
- ğŸ¯ **Preset Emotions**: Quick-select from 8 common emotion combinations
- âœ¨ **One Keyword at a Time**: Add emotion keywords individually for precise control

## ğŸš€ Quick Start

### Local Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run the app:
```bash
streamlit run app.py
```

3. Open your browser at `http://localhost:8501`

## ğŸŒ Deploy to HuggingFace Spaces

1. Create a new Space on [HuggingFace](https://huggingface.co/spaces)
2. Select "Streamlit" as the SDK
3. Upload these files:
   - `app.py`
   - `requirements.txt`
   - `README.md`
   - Copy the `model/` folder with trained models
   - Copy the `data/` folder with dataset

4. Your app will be live at `https://huggingface.co/spaces/YOUR_USERNAME/emotion2music`

## ğŸ“ Required Files

```
Emotion2Music/
â”œâ”€â”€ app.py                          # Main Streamlit app
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ model/
â”‚   â””â”€â”€ va_2d_model.pth            # Trained model
â””â”€â”€ data/
    â””â”€â”€ top3_themes_with_vad_mood_900.tsv  # Dataset
```

## ğŸ¯ How It Works

1. **Input**: User adds emotional keywords one at a time (e.g., "happy", "energetic", "dancing")
   - Keywords appear as animated bubbles in the Emotion Area
   - Users can add keywords individually or select preset combinations
2. **VAD Conversion**: Keywords are converted to Valence-Arousal-Dominance values using NRC-VAD lexicon
3. **Prediction**: Neural network predicts mood category and BPM
4. **Retrieval**: System finds the best matching song from database
5. **Playback**: Audio streams from Jamendo API

## ğŸ¨ Model Architecture

- **Input**: 2D (Valence, Arousal) or 3D (Valence, Arousal, Dominance)
- **Architecture**: Multi-layer perceptron with dual heads
  - Classification head: Predicts mood category
  - Regression head: Predicts BPM
- **Training**: Multi-task learning with combined loss

## ğŸµ Supported Moods

The model can predict various moods including:
- Happy, Sad, Calm, Energetic
- Dark, Romantic, Aggressive
- And more...

## ğŸ“Š Dataset

- **Source**: MTG-Jamendo Dataset
- **Size**: 900+ annotated tracks
- **Features**: Mood tags, BPM, VAD values

## ğŸ¤ Credits

- **Dataset**: MTG-Jamendo Dataset
- **Lexicon**: NRC-VAD-Lexicon
- **Music API**: Jamendo API
- **Framework**: Streamlit, PyTorch

## ğŸ“ License

This project is for educational purposes. Please check the licenses of individual components:
- MTG-Jamendo Dataset: [License](https://mtg.github.io/mtg-jamendo-dataset/)
- Jamendo Music: Creative Commons licensed tracks

Made with â¤ï¸ using Streamlit, PyTorch & Jamendo API

